This is the video transcript:

hello, my name is eric lawson and today we will be going over the prototypes in relation to the documentation that I have provided in the github project. so first we are going to be concerned with the prerequisites (goes over that and the examples of the prototype with python to verify the results)

so now we are going to look into the prototype code and understand how the prototype is a proof of concept for objectifying reason, operationalizing it, and integrating context. And these 3 factors are also important in understanding how a DSL for universal reasoning would be constructed.

(slide Objectifying reason + key words)

Objectifying reason takes place through combinatorial layering (highlights that part in the prototype) which is described here and within this process is the pruning and ordering function (highlights that). This ordering and pruning function is the POT generator function. These are the definitions of the POT generator functions (highlights them). what is interesting about the POT generator function in these prototypes is that they do not integrate context at the POT generator function level. This goes into how context  POT generators can be dependent not only on context being integrated the POT generator but how it can also be integrated through operationalization of reasoning itself as an object. So this goes into the concept of how the fluidity between reasoning objectified with the pot generator and combinatorial layering will be influenced by the context integration and the operationalization of the reasoning itself.

(operationalization of reasoning object (RDU) slide + key words) 

so once that we understand briefly the objectification of reasoning through combinatorial layering and POT generator functions in the prototype, how does that influence operationalization? Well you see the POT generator function in these reasoning units is going to be based on the idea that we are going to be collecting on a layer and these two (highlighting the two functions) functions are separated based on the need for context integration which we will go into in the context integration segment, but here what we are worried about is how collecting from the layer influenced the POT generator because you see rather than path transversal which is how uh all the previous documentation leading up to this has considered operationalization. Here we are considering collecting on a layer rather than a path so collecting on a layer considers evaluating all of the potential combinatorial outcomes uh at this combinatorial step. and performing an operation on that layer which can be understood when you look at the prototype code itself. but what we are considering is the operationalization based on the POT generation took place because we are considering reasoning through the lens of collecting all the combinatorial object here. Rather than choosing a path through the reasoning space. So we are performing an operation on the layering format. This shows that there is multiple different operations in reasoning beyond path transversal and this prototype is not only a proof of concept of reasoning objectified and operationalized but it also shows that operations can go beyond simply path transversal, even though currently there is not a DSL catering towards reasoning being objectified.

Another important thing to consider within the prototype is that with this operationalization we have an example here where the convoluted partial bell polynomial is actually dependent on composing the predefined bell polynomial proof object here. So this not only shows that reasoning can be objectified but it can be composed. So as you can see from up here, (highlighting two functions compose and predefined object) this is why there is a separation of the predefined bell polynomial object and the composition. if you actually look closely the only difference is that the composition one is returning a value and the other one is returning an object. And this goes to show how the rigid parameterization within python can be an issue when you are working with reasoning being an object and a first class citizen.

(Context integration into reasoning object (RDU) slide + keywords)

 as previously mentioned before, there is also the context integration, so the context integration is not happening at the POT generator function level here (highlights POT generator functions) but rather the operationalization of (highlights collect from layers functions) the reasoning object. These (Highlighting POT generator functions) are actually combinatorial primitives for the POT generator so these dont actually describe any context but rather skeleton of combinatorics itself which is where the structure emerges. The collection of the layer integrates a term function, a subdag function, collection function, and a transformation function which is the context integration based on the combinatorial skeleton. The difference between these two (highlighting the layer collection functions) functions is that one is the collection of layering and the other is collection of layering which is root dependent is that the context integration in this python prototype is dependent on... for instance if we look at the composite reasoning one (pointing to convoluted partial bell polynomial example) requires the collection here (root dependent function) to have a different context integration. Otherwise if you look in the examples we had here (for convoluted) (I point out verbally and pointing to result how it is convoluted based on structure based on f0 and f1) the context integration for the 0 and 1 denomination of these functions occurs at the layer collection and is based on the root the proof object and that is where we get the integration of the context of whether this is going to be arbitrary function 0 or arbitrary function 1(pointing to example). And this (highlighting 2 layer collection functions) is a matter of a difference in context integration. In a DSL this would be more considered due to having to balance the trifecta of objectifying reasoning, operationalizing it, and integrating context. Hopefully throughout the uh prototype code you can see how the rigid parameterization of python and these other languages restricts the ability for free flow uh sandbox sort of construction and testing of reasoning in the way described here. 

(conclusion slide)

so in the end, hopefully this video has properly articulated the balance and the fluidity needed between how we objectify reasoning, how we operationalize it, and integrate context into it. As well as how this is going to help with understanding how we formulate a DSL for which this reasoning object can be manipulated properly and enable automated uh systematic exploration and discovery of reasoning itself. and it can be understood that considering we haven't really even considered path transversal as an operation with these proof objects it is still possible look through the object in terms of path transversal. So it is systemically emergent that other operations on this reasoning object may yield non-linear outcomes, which is the potential beginning of the new emergence of science based on the objectification of reasoning. And we can go more into this based on the documentation where I describe how chess can be approached as creating a reasoning space where machine learning can be utilized to create models that would overfit the chess reasoning space and I would love for you all to go and look through the documentation further because I believe that we together can build reasoning and can create a world that we as of now can only dream of understanding.